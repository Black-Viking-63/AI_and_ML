{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "import theano as th\n",
    "import theano.tensor as T\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data and create DataFrame from it\n",
    "data = pd.read_csv('16.csv', sep=';').replace(['DZN', 'Makula', 'SoftExudates', 'Vessels'], [0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>name</th>\n",
       "      <th>area</th>\n",
       "      <th>class</th>\n",
       "      <th>gray_Mean</th>\n",
       "      <th>gray_Variance</th>\n",
       "      <th>gray_Skewness</th>\n",
       "      <th>gray_Kurtosis</th>\n",
       "      <th>gray_Perc.01%</th>\n",
       "      <th>gray_Perc.10%</th>\n",
       "      <th>...</th>\n",
       "      <th>b_S(5,-5)SumVarnc</th>\n",
       "      <th>b_S(5,-5)SumEntrp</th>\n",
       "      <th>b_S(5,-5)Entropy</th>\n",
       "      <th>b_S(5,-5)DifVarnc</th>\n",
       "      <th>b_S(5,-5)DifEntrp</th>\n",
       "      <th>b_GrMean</th>\n",
       "      <th>b_GrVariance</th>\n",
       "      <th>b_GrSkewness</th>\n",
       "      <th>b_GrKurtosis</th>\n",
       "      <th>b_GrNonZeros</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>504914</td>\n",
       "      <td>25-May-2012 12-44-02</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>162,87</td>\n",
       "      <td>25,6731</td>\n",
       "      <td>0,0556933442808038</td>\n",
       "      <td>-0,847312470433456</td>\n",
       "      <td>153,0</td>\n",
       "      <td>156,0</td>\n",
       "      <td>...</td>\n",
       "      <td>19020,2920239063</td>\n",
       "      <td>1,0185245113550199</td>\n",
       "      <td>1,59059920589699</td>\n",
       "      <td>37,6861925522195</td>\n",
       "      <td>1,00034500883477</td>\n",
       "      <td>4,04366697163015</td>\n",
       "      <td>4,68000742254742</td>\n",
       "      <td>0,469840716855728</td>\n",
       "      <td>-0,739006133152813</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>504915</td>\n",
       "      <td>25-May-2012 12-44-02</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>163,22</td>\n",
       "      <td>34,0916</td>\n",
       "      <td>-0,184628743255271</td>\n",
       "      <td>-1,17512428138866</td>\n",
       "      <td>152,0</td>\n",
       "      <td>155,0</td>\n",
       "      <td>...</td>\n",
       "      <td>18872,185673506498</td>\n",
       "      <td>1,12394386122761</td>\n",
       "      <td>1,62672280537666</td>\n",
       "      <td>27,945501012950896</td>\n",
       "      <td>0,861753508048933</td>\n",
       "      <td>4,51488268129824</td>\n",
       "      <td>4,38145937411324</td>\n",
       "      <td>0,139565167526377</td>\n",
       "      <td>-0,8441575745042179</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>504916</td>\n",
       "      <td>25-May-2012 12-44-02</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>166,02</td>\n",
       "      <td>36,3396</td>\n",
       "      <td>-0,213090557717068</td>\n",
       "      <td>-1,34859723534067</td>\n",
       "      <td>155,0</td>\n",
       "      <td>158,0</td>\n",
       "      <td>...</td>\n",
       "      <td>18936,2296403973</td>\n",
       "      <td>0,9450748123142929</td>\n",
       "      <td>1,50017250441739</td>\n",
       "      <td>34,9389659370051</td>\n",
       "      <td>0,9521802095285329</td>\n",
       "      <td>3,42635982214587</td>\n",
       "      <td>2,77568336918453</td>\n",
       "      <td>0,258781983309002</td>\n",
       "      <td>-0,45019100421053404</td>\n",
       "      <td>0,96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>504917</td>\n",
       "      <td>25-May-2012 12-44-02</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>163,57</td>\n",
       "      <td>32,7051</td>\n",
       "      <td>-0,23953206151099998</td>\n",
       "      <td>-0,7412659193903579</td>\n",
       "      <td>151,0</td>\n",
       "      <td>155,0</td>\n",
       "      <td>...</td>\n",
       "      <td>19341,6490470399</td>\n",
       "      <td>1,0185245113550199</td>\n",
       "      <td>1,5694682548103003</td>\n",
       "      <td>21,2180474577127</td>\n",
       "      <td>0,793004206059718</td>\n",
       "      <td>3,5684615219362903</td>\n",
       "      <td>3,68795736646017</td>\n",
       "      <td>0,44332061765059905</td>\n",
       "      <td>0,0231065255473104</td>\n",
       "      <td>0,953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>504918</td>\n",
       "      <td>25-May-2012 12-44-02</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>162,73</td>\n",
       "      <td>35,4571</td>\n",
       "      <td>-0,0356651425692793</td>\n",
       "      <td>-1,45781568758918</td>\n",
       "      <td>153,0</td>\n",
       "      <td>155,0</td>\n",
       "      <td>...</td>\n",
       "      <td>18475,989997983</td>\n",
       "      <td>0,9944421117018969</td>\n",
       "      <td>1,63876400520322</td>\n",
       "      <td>45,426724314094706</td>\n",
       "      <td>0,9944421117018969</td>\n",
       "      <td>4,28622945998813</td>\n",
       "      <td>4,92511201632983</td>\n",
       "      <td>-0,0128182902511431</td>\n",
       "      <td>-1,1049856517508898</td>\n",
       "      <td>1,0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 940 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  name  area  class gray_Mean gray_Variance  \\\n",
       "0      504914  25-May-2012 12-44-02   100      0    162,87       25,6731   \n",
       "1      504915  25-May-2012 12-44-02   100      0    163,22       34,0916   \n",
       "2      504916  25-May-2012 12-44-02   100      0    166,02       36,3396   \n",
       "3      504917  25-May-2012 12-44-02   100      0    163,57       32,7051   \n",
       "4      504918  25-May-2012 12-44-02   100      0    162,73       35,4571   \n",
       "\n",
       "          gray_Skewness        gray_Kurtosis gray_Perc.01% gray_Perc.10%  \\\n",
       "0    0,0556933442808038   -0,847312470433456         153,0         156,0   \n",
       "1    -0,184628743255271    -1,17512428138866         152,0         155,0   \n",
       "2    -0,213090557717068    -1,34859723534067         155,0         158,0   \n",
       "3  -0,23953206151099998  -0,7412659193903579         151,0         155,0   \n",
       "4   -0,0356651425692793    -1,45781568758918         153,0         155,0   \n",
       "\n",
       "      ...        b_S(5,-5)SumVarnc   b_S(5,-5)SumEntrp    b_S(5,-5)Entropy  \\\n",
       "0     ...         19020,2920239063  1,0185245113550199    1,59059920589699   \n",
       "1     ...       18872,185673506498    1,12394386122761    1,62672280537666   \n",
       "2     ...         18936,2296403973  0,9450748123142929    1,50017250441739   \n",
       "3     ...         19341,6490470399  1,0185245113550199  1,5694682548103003   \n",
       "4     ...          18475,989997983  0,9944421117018969    1,63876400520322   \n",
       "\n",
       "    b_S(5,-5)DifVarnc   b_S(5,-5)DifEntrp            b_GrMean  \\\n",
       "0    37,6861925522195    1,00034500883477    4,04366697163015   \n",
       "1  27,945501012950896   0,861753508048933    4,51488268129824   \n",
       "2    34,9389659370051  0,9521802095285329    3,42635982214587   \n",
       "3    21,2180474577127   0,793004206059718  3,5684615219362903   \n",
       "4  45,426724314094706  0,9944421117018969    4,28622945998813   \n",
       "\n",
       "       b_GrVariance         b_GrSkewness          b_GrKurtosis b_GrNonZeros  \n",
       "0  4,68000742254742    0,469840716855728    -0,739006133152813          1,0  \n",
       "1  4,38145937411324    0,139565167526377   -0,8441575745042179          1,0  \n",
       "2  2,77568336918453    0,258781983309002  -0,45019100421053404      0,96875  \n",
       "3  3,68795736646017  0,44332061765059905    0,0231065255473104     0,953125  \n",
       "4  4,92511201632983  -0,0128182902511431   -1,1049856517508898          1,0  \n",
       "\n",
       "[5 rows x 940 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check a few rows of the table\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    6004\n",
      "1    3517\n",
      "2    2454\n",
      "3    1079\n",
      "Name: class, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = data['class']\n",
    "print(y.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data.pop('class')\n",
    "#даже если переводить всё это дело в таймстамп, получается так себе\n",
    "data.pop('name')\n",
    "x = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#форматируем всю х***ю\n",
    "#datePattern = '%d-%B-%Y %H-%M-%S'\n",
    "cols = x.columns\n",
    "#for index, row in x.head().iterrows():\n",
    "for index, row in x.iterrows():\n",
    "    #мутирущий код зло, но мне лень -_-\n",
    "    #if (isinstance(x.at[index, 'name'], str)):\n",
    "    #    trueDate = datetime.strptime(x.at[index, 'name'], datePattern)\n",
    "    #    x.at[index, 'name'] = datetime.timestamp(trueDate)\n",
    "    \n",
    "    for col in cols:\n",
    "        if (isinstance(x.at[index, col], str)):\n",
    "            x.at[index, col] = x.at[index, col].replace(',', '.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#меням тип\n",
    "for col in cols:\n",
    "    x[col] = pd.to_numeric(x[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#сдвигаем отрицательные\n",
    "for col in cols:\n",
    "    minColVal = x[col].min()\n",
    "    if (minColVal < 0):\n",
    "        for index, row in x.iterrows():\n",
    "            x.at[index, col] -= minColVal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0               int64\n",
       "area                     int64\n",
       "gray_Mean              float64\n",
       "gray_Variance          float64\n",
       "gray_Skewness          float64\n",
       "gray_Kurtosis          float64\n",
       "gray_Perc.01%          float64\n",
       "gray_Perc.10%          float64\n",
       "gray_Perc.50%          float64\n",
       "gray_Perc.90%          float64\n",
       "gray_Perc.99%          float64\n",
       "gray_S(1,0)AngScMom    float64\n",
       "gray_S(1,0)Contrast    float64\n",
       "gray_S(1,0)Correlat    float64\n",
       "gray_S(1,0)SumOfSqs    float64\n",
       "gray_S(1,0)InvDfMom    float64\n",
       "gray_S(1,0)SumAverg    float64\n",
       "gray_S(1,0)SumVarnc    float64\n",
       "gray_S(1,0)SumEntrp    float64\n",
       "gray_S(1,0)Entropy     float64\n",
       "gray_S(1,0)DifVarnc    float64\n",
       "gray_S(1,0)DifEntrp    float64\n",
       "gray_S(0,1)AngScMom    float64\n",
       "gray_S(0,1)Contrast    float64\n",
       "gray_S(0,1)Correlat    float64\n",
       "gray_S(0,1)SumOfSqs    float64\n",
       "gray_S(0,1)InvDfMom    float64\n",
       "gray_S(0,1)SumAverg    float64\n",
       "gray_S(0,1)SumVarnc    float64\n",
       "gray_S(0,1)SumEntrp    float64\n",
       "                        ...   \n",
       "b_S(0,5)Entropy        float64\n",
       "b_S(0,5)DifVarnc       float64\n",
       "b_S(0,5)DifEntrp       float64\n",
       "b_S(5,5)AngScMom       float64\n",
       "b_S(5,5)Contrast       float64\n",
       "b_S(5,5)Correlat       float64\n",
       "b_S(5,5)SumOfSqs       float64\n",
       "b_S(5,5)InvDfMom       float64\n",
       "b_S(5,5)SumAverg       float64\n",
       "b_S(5,5)SumVarnc       float64\n",
       "b_S(5,5)SumEntrp       float64\n",
       "b_S(5,5)Entropy        float64\n",
       "b_S(5,5)DifVarnc       float64\n",
       "b_S(5,5)DifEntrp       float64\n",
       "b_S(5,-5)AngScMom      float64\n",
       "b_S(5,-5)Contrast      float64\n",
       "b_S(5,-5)Correlat      float64\n",
       "b_S(5,-5)SumOfSqs      float64\n",
       "b_S(5,-5)InvDfMom      float64\n",
       "b_S(5,-5)SumAverg      float64\n",
       "b_S(5,-5)SumVarnc      float64\n",
       "b_S(5,-5)SumEntrp      float64\n",
       "b_S(5,-5)Entropy       float64\n",
       "b_S(5,-5)DifVarnc      float64\n",
       "b_S(5,-5)DifEntrp      float64\n",
       "b_GrMean               float64\n",
       "b_GrVariance           float64\n",
       "b_GrSkewness           float64\n",
       "b_GrKurtosis           float64\n",
       "b_GrNonZeros           float64\n",
       "Length: 938, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4\n",
    "K = 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by the scale function.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 6.72184017e-01 ... 4.42243172e-01\n",
      "  6.29448677e-02 1.00000000e+00]\n",
      " [7.66107408e-05 0.00000000e+00 6.73843965e-01 ... 3.44791273e-01\n",
      "  5.49957911e-02 1.00000000e+00]\n",
      " [1.53221482e-04 0.00000000e+00 6.87123548e-01 ... 3.79967674e-01\n",
      "  8.47782687e-02 9.09090909e-01]\n",
      " ...\n",
      " [9.99846779e-01 1.00000000e+00 2.83886649e-01 ... 4.89072869e-01\n",
      "  1.43858074e-01 9.37149270e-01]\n",
      " [9.99923389e-01 1.00000000e+00 2.52157932e-01 ... 4.62395601e-01\n",
      "  1.43714671e-01 8.92255892e-01]\n",
      " [1.00000000e+00 1.00000000e+00 2.66492767e-01 ... 4.95572304e-01\n",
      "  1.42125996e-01 8.83277217e-01]]\n"
     ]
    }
   ],
   "source": [
    "stand_X = preprocessing.scale(x)\n",
    "norm_X = preprocessing.MinMaxScaler().fit_transform(stand_X)\n",
    "print(norm_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = SelectKBest(score_func=chi2, k= N + K)\n",
    "fit_k = best_features.fit(norm_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/ensemble/forest.py:246: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "accuracy_Kbest = []\n",
    "model_norm = SGDClassifier(loss='log', penalty='l1', l1_ratio=1.)\n",
    "best_features = pd.DataFrame(data=fit_k.scores_, index=x.columns, columns=['chi2_score'])\n",
    "accuracy_trees = []\n",
    "model_tree = ExtraTreesClassifier().fit(norm_X, y)\n",
    "importance_features = pd.DataFrame(data=model_tree.feature_importances_, index=x.columns, columns=['feature_importance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc',\n",
      "       'r_S(2,0)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc',\n",
      "       'g_S(2,2)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc',\n",
      "       'r_S(2,0)SumVarnc', 'r_S(0,1)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc',\n",
      "       'g_S(2,2)SumAverg', 'gray_S(1,0)SumAverg'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc',\n",
      "       'r_S(2,0)SumVarnc', 'r_S(0,1)SumVarnc', 'r_S(0,5)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc',\n",
      "       'g_S(2,2)SumAverg', 'gray_S(1,0)SumAverg', 'gray_Mean'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc',\n",
      "       'r_S(2,0)SumVarnc', 'r_S(0,1)SumVarnc', 'r_S(0,5)SumVarnc',\n",
      "       'r_S(1,0)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc',\n",
      "       'g_S(2,2)SumAverg', 'gray_S(1,0)SumAverg', 'gray_Mean',\n",
      "       'r_S(5,0)DifEntrp'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 features: \n",
      "\t Kbest: Index(['r_S(3,-3)SumVarnc', 'r_S(3,3)SumVarnc', 'r_S(2,2)SumVarnc',\n",
      "       'r_S(2,-2)SumVarnc', 'r_S(4,-4)SumVarnc', 'r_S(0,3)SumVarnc',\n",
      "       'r_S(4,4)SumVarnc', 'r_S(1,-1)SumVarnc', 'r_S(0,2)SumVarnc',\n",
      "       'r_S(0,4)SumVarnc', 'r_S(3,0)SumVarnc', 'r_S(1,1)SumVarnc',\n",
      "       'r_S(5,-5)SumVarnc', 'r_S(4,0)SumVarnc', 'r_S(5,0)SumVarnc',\n",
      "       'r_S(2,0)SumVarnc', 'r_S(0,1)SumVarnc', 'r_S(0,5)SumVarnc',\n",
      "       'r_S(1,0)SumVarnc', 'r_S(5,5)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Trees: Index(['r_S(1,0)SumAverg', 'r_S(4,4)SumVarnc', 'b_S(0,1)SumAverg',\n",
      "       'r_S(0,3)SumVarnc', 'g_S(4,4)SumAverg', 'g_S(1,1)SumAverg',\n",
      "       'g_S(1,-1)SumAverg', 'gray_S(3,3)SumAverg', 'r_Perc.50%',\n",
      "       'r_S(0,1)SumAverg', 'r_S(5,-5)SumAverg', 'gray_S(0,1)SumVarnc',\n",
      "       'b_S(3,3)DifEntrp', 'r_S(0,4)SumVarnc', 'r_S(4,-4)SumVarnc',\n",
      "       'g_S(2,2)SumAverg', 'gray_S(1,0)SumAverg', 'gray_Mean',\n",
      "       'r_S(5,0)DifEntrp', 'r_S(0,1)SumVarnc'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      " Accuracy Kbest:  [0.7787670465375598, 0.7883285053282056, 0.8068833529092382, 0.7949243268546488, 0.8005892794843511, 0.7790088531872412, 0.8167717518378798, 0.792395856436026, 0.8007515494217421, 0.8013629327372996, 0.803131846259993, 0.8112531052474843, 0.809711171571007, 0.7828239159187917, 0.798449617073166, 0.8238855675275089, 0.7966919495021574]\n",
      " \n",
      " Accuracy trees:  [0.9299136531519814, 0.9505173808850275, 0.9499823621021729, 0.9497514793600537, 0.9492927655137479, 0.9535055945217149, 0.9489079499988465, 0.9523571666488271, 0.9524334138783075, 0.9571828468818477, 0.9576404149977149, 0.9586376119850415, 0.9587145041123757, 0.9580247019734422, 0.9561086104634857, 0.9596326357592562, 0.9564933085402298]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for i in range(N, N + K):\n",
    "    print(i, 'features: ')\n",
    "    best = best_features.nlargest(i, 'chi2_score').index\n",
    "    print('\\t Kbest:', best)\n",
    "    kbest_x = x[best]\n",
    "    kbest_cvs = cross_val_score(model_norm, (kbest_x - kbest_x.mean(axis=0))/kbest_x.std(axis=0), y, cv = 5)\n",
    "    accuracy_Kbest.append(np.mean(kbest_cvs))\n",
    "    importance = importance_features.nlargest(i, 'feature_importance').index\n",
    "    print('\\t Trees:', importance)\n",
    "    tree_x = x[importance]\n",
    "    trees_cvs = cross_val_score(model_norm, (tree_x - tree_x.mean(axis=0))/tree_x.std(axis=0), y, cv = 5)\n",
    "    accuracy_trees.append(np.mean(trees_cvs))\n",
    "print(' \\n Accuracy Kbest: ' ,accuracy_Kbest)\n",
    "print(' \\n Accuracy trees: ' ,accuracy_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "count = range(N, N+K)\n",
    "plt.plot(count, accuracy_Kbest, color='darkgreen', label='Kbest')\n",
    "plt.plot(count, accuracy_trees, color='m', label='Tree')\n",
    "plt.xlabel('Count features')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Top features')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_features = preprocessing.scale(preprocessing.MinMaxScaler().fit_transform(x[['b_S(4,0)SumVarnc', 'b_Perc.01%', 'b_S(4,-4)SumVarnc',\n",
    "       'gray_S(0,3)SumAverg', 'b_S(0,2)SumAverg', 'gray_S(0,3)SumVarnc',\n",
    "       'g_Perc.99%', 'r_S(4,4)SumVarnc', 'g_S(2,-2)SumVarnc', 'gray_Perc.01%',\n",
    "       'b_Perc.90%', 'b_S(3,-3)SumVarnc', 'b_S(2,0)SumAverg',\n",
    "       'gray_S(5,0)SumVarnc', 'b_S(5,5)SumAverg']]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=0.01\n",
    "\n",
    "def init_weights(D, H):\n",
    "    W = np.random.randn(D, H) / np.sqrt(D)\n",
    "    b = np.zeros(H)\n",
    "    \n",
    "    W = th.shared(W)\n",
    "    b = th.shared(b)\n",
    "    return W, b\n",
    "    \n",
    "\n",
    "def create_layer(x, W, b, activation=T.tanh):\n",
    "    x = T.dot(x, W) + b\n",
    "    if activation is not None:\n",
    "        x = activation(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X, Y, count_neurons, epochs):\n",
    "    print('test')\n",
    "    x = T.vector('x')\n",
    "\n",
    "    W1, b1 = init_weights(D=15, H=count_neurons)\n",
    "    out_l1 = create_layer(x, W1, b1)\n",
    "\n",
    "    W2, b2 = init_weights(D=count_neurons, H=len(np.unique(Y)))\n",
    "    out_l2 = create_layer(out_l1, W2, b2, activation=None)\n",
    "    \n",
    "    classification_out = T.nnet.softmax(out_l2)\n",
    "\n",
    "    softmax_out = th.function(\n",
    "        inputs=[x],\n",
    "        outputs=classification_out\n",
    "    )\n",
    "    \n",
    "    loss = -T.log(classification_out + 1e-13)\n",
    "    \n",
    "    label = T.scalar('y', dtype=T.int32) \n",
    "\n",
    "    class_loss = loss[0, label]\n",
    "\n",
    "    loss_val = th.function(\n",
    "        inputs=[x, label],\n",
    "        outputs=class_loss\n",
    "    )\n",
    "    \n",
    "    W1_grad = T.grad(class_loss, W1)\n",
    "    b1_grad = T.grad(class_loss, b1)\n",
    "    W2_grad = T.grad(class_loss, W2)\n",
    "    b2_grad = T.grad(class_loss, b2)\n",
    "\n",
    "    update_W1 = W1 - learning_rate * W1_grad\n",
    "    update_b1 = b1 - learning_rate * b1_grad\n",
    "    update_W2 = W2 - learning_rate * W2_grad\n",
    "    update_b2 = b2 - learning_rate * b2_grad\n",
    "\n",
    "    updates = [\n",
    "        (W1, update_W1),\n",
    "        (b1, update_b1),\n",
    "        (W2, update_W2),\n",
    "        (b2, update_b2)\n",
    "    ]\n",
    "\n",
    "    train_op = th.function(\n",
    "        inputs=[x, label],\n",
    "        outputs=class_loss,\n",
    "        updates=updates\n",
    "    )\n",
    "    \n",
    "    accuracy = []\n",
    "    loss = []\n",
    "    time_train = 0\n",
    "    for i in range(epochs):\n",
    "        for j in range(len(X)):\n",
    "            label = Y[j]\n",
    "            x_in = X[j]\n",
    "            start = time.time()\n",
    "            #print(x_in)\n",
    "            #print(label)\n",
    "            _ = train_op(x_in, label)\n",
    "            end = time.time()\n",
    "            time_train += (end - start)\n",
    "        n_correct = 0\n",
    "        loss_values = []\n",
    "        for j in range(len(X)):\n",
    "            label = Y[j]\n",
    "            x_in = X[j]\n",
    "            loss_values += [loss_val(x_in, label)]\n",
    "            answer = softmax_out(x_in)\n",
    "\n",
    "            n_correct += np.argmax(answer[0]) == label\n",
    "        accuracy.append(n_correct / len(X))\n",
    "        loss.append(sum(loss_values) / len(X))\n",
    "        print('Accuracy:', accuracy[-1])\n",
    "        print('Mean loss:', loss[-1])\n",
    "        print(str(i+1)+'/'+str(epochs))\n",
    "    \n",
    "    return [accuracy, loss, time_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#zzz = {'DZN': 0, 'Makula': 1, 'SoftExudates': 2, 'Vessels': 3}\n",
    "#for i in range(0, y.size):\n",
    "#    y[i] = zzz[y[i]]\n",
    "    \n",
    "#print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden neurons: 15\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7459016393442623\n",
      "Mean loss: 0.6989838038892336\n",
      "1/30\n",
      "Accuracy: 0.7571625555385323\n",
      "Mean loss: 0.625462033556095\n",
      "2/30\n",
      "Accuracy: 0.7787651294622338\n",
      "Mean loss: 0.5889986889746003\n",
      "3/30\n",
      "Accuracy: 0.7975333231193504\n",
      "Mean loss: 0.5627961971807837\n",
      "4/30\n",
      "Accuracy: 0.8148460242071396\n",
      "Mean loss: 0.5400688498295503\n",
      "5/30\n",
      "Accuracy: 0.8287115060517849\n",
      "Mean loss: 0.516102109406982\n",
      "6/30\n",
      "Accuracy: 0.8356825494101425\n",
      "Mean loss: 0.4938735407190659\n",
      "7/30\n",
      "Accuracy: 0.8412747050712426\n",
      "Mean loss: 0.4728086323963402\n",
      "8/30\n",
      "Accuracy: 0.8459476022675042\n",
      "Mean loss: 0.4524212850836021\n",
      "9/30\n",
      "Accuracy: 0.8503906848475563\n",
      "Mean loss: 0.43029474482180446\n",
      "10/30\n",
      "Accuracy: 0.8562892599969358\n",
      "Mean loss: 0.4092517933199203\n",
      "11/30\n",
      "Accuracy: 0.860119503600429\n",
      "Mean loss: 0.3944035374416775\n",
      "12/30\n",
      "Accuracy: 0.8639497472039221\n",
      "Mean loss: 0.38625044191798175\n",
      "13/30\n",
      "Accuracy: 0.8660946836218784\n",
      "Mean loss: 0.3856614857461653\n",
      "14/30\n",
      "Accuracy: 0.8689290638884634\n",
      "Mean loss: 0.3883255915585583\n",
      "15/30\n",
      "Accuracy: 0.8731423318523058\n",
      "Mean loss: 0.3840135109771301\n",
      "16/30\n",
      "Accuracy: 0.8772789949440785\n",
      "Mean loss: 0.382773978880636\n",
      "17/30\n",
      "Accuracy: 0.88762065267351\n",
      "Mean loss: 0.3702686883527592\n",
      "18/30\n",
      "Accuracy: 0.8929829937184005\n",
      "Mean loss: 0.36309117103946636\n",
      "19/30\n",
      "Accuracy: 0.8975026811705225\n",
      "Mean loss: 0.3578250236847101\n",
      "20/30\n",
      "Accuracy: 0.8994944078443389\n",
      "Mean loss: 0.3537822612677512\n",
      "21/30\n",
      "Accuracy: 0.9021755783667841\n",
      "Mean loss: 0.3479288602410001\n",
      "22/30\n",
      "Accuracy: 0.9050099586333691\n",
      "Mean loss: 0.3431818376111993\n",
      "23/30\n",
      "Accuracy: 0.9086103876206527\n",
      "Mean loss: 0.33638945672621523\n",
      "24/30\n",
      "Accuracy: 0.910678719166539\n",
      "Mean loss: 0.3302901366225409\n",
      "25/30\n",
      "Accuracy: 0.9137429140493335\n",
      "Mean loss: 0.32276522565279053\n",
      "26/30\n",
      "Accuracy: 0.9159644553393596\n",
      "Mean loss: 0.31529711516811704\n",
      "27/30\n",
      "Accuracy: 0.9195648843266432\n",
      "Mean loss: 0.3071857286122895\n",
      "28/30\n",
      "Accuracy: 0.9218630304887391\n",
      "Mean loss: 0.2988806636528224\n",
      "29/30\n",
      "Accuracy: 0.9244675961391144\n",
      "Mean loss: 0.29042524123682406\n",
      "30/30\n",
      "Hidden neurons: 50\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.746667688064961\n",
      "Mean loss: 0.8034400680170665\n",
      "1/30\n",
      "Accuracy: 0.76405699402482\n",
      "Mean loss: 0.7250181946900658\n",
      "2/30\n",
      "Accuracy: 0.7829017925540064\n",
      "Mean loss: 0.6626442550769657\n",
      "3/30\n",
      "Accuracy: 0.7957714110617435\n",
      "Mean loss: 0.6323997304555607\n",
      "4/30\n",
      "Accuracy: 0.8072621418722231\n",
      "Mean loss: 0.6128216542761264\n",
      "5/30\n",
      "Accuracy: 0.8189060824268424\n",
      "Mean loss: 0.5868905535516415\n",
      "6/30\n",
      "Accuracy: 0.8289413206679945\n",
      "Mean loss: 0.551551890788601\n",
      "7/30\n",
      "Accuracy: 0.8357591542822124\n",
      "Mean loss: 0.5133571116919102\n",
      "8/30\n",
      "Accuracy: 0.840508656350544\n",
      "Mean loss: 0.47986101771692324\n",
      "9/30\n",
      "Accuracy: 0.8461008120116439\n",
      "Mean loss: 0.4527896877064869\n",
      "10/30\n",
      "Accuracy: 0.8517695725448139\n",
      "Mean loss: 0.4318561786814476\n",
      "11/30\n",
      "Accuracy: 0.8585874061590317\n",
      "Mean loss: 0.4166926362335098\n",
      "12/30\n",
      "Accuracy: 0.862953883867014\n",
      "Mean loss: 0.40593674270845476\n",
      "13/30\n",
      "Accuracy: 0.8667075225984373\n",
      "Mean loss: 0.3984527501457571\n",
      "14/30\n",
      "Accuracy: 0.8704611613298606\n",
      "Mean loss: 0.39343847837615664\n",
      "15/30\n",
      "Accuracy: 0.8745212195495633\n",
      "Mean loss: 0.390418301005714\n",
      "16/30\n",
      "Accuracy: 0.876972575455799\n",
      "Mean loss: 0.38867221728622736\n",
      "17/30\n",
      "Accuracy: 0.8809560288034319\n",
      "Mean loss: 0.3878228579145652\n",
      "18/30\n",
      "Accuracy: 0.8833307798375977\n",
      "Mean loss: 0.38744686807830814\n",
      "19/30\n",
      "Accuracy: 0.8857055308717634\n",
      "Mean loss: 0.3871841233269501\n",
      "20/30\n",
      "Accuracy: 0.8867779990807415\n",
      "Mean loss: 0.38638136723915323\n",
      "21/30\n",
      "Accuracy: 0.8883867013942087\n",
      "Mean loss: 0.3843720374543479\n",
      "22/30\n",
      "Accuracy: 0.8903784280680251\n",
      "Mean loss: 0.38125332356988706\n",
      "23/30\n",
      "Accuracy: 0.8916041060211429\n",
      "Mean loss: 0.37850092915080014\n",
      "24/30\n",
      "Accuracy: 0.8931362034625402\n",
      "Mean loss: 0.3775695736531205\n",
      "25/30\n",
      "Accuracy: 0.8942852765435881\n",
      "Mean loss: 0.3785016345603024\n",
      "26/30\n",
      "Accuracy: 0.8949747203922169\n",
      "Mean loss: 0.38030453113645074\n",
      "27/30\n",
      "Accuracy: 0.896047188601195\n",
      "Mean loss: 0.3821142265967284\n",
      "28/30\n",
      "Accuracy: 0.8968132373218937\n",
      "Mean loss: 0.3835635691385178\n",
      "29/30\n",
      "Accuracy: 0.8975026811705225\n",
      "Mean loss: 0.38441879678385166\n",
      "30/30\n",
      "Hidden neurons: 100\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7695725448138502\n",
      "Mean loss: 0.7685798055117273\n",
      "1/30\n",
      "Accuracy: 0.7920177723303202\n",
      "Mean loss: 0.6560422948166471\n",
      "2/30\n",
      "Accuracy: 0.8064194882794545\n",
      "Mean loss: 0.6060324301454203\n",
      "3/30\n",
      "Accuracy: 0.8165313313926765\n",
      "Mean loss: 0.578582298490033\n",
      "4/30\n",
      "Accuracy: 0.826413359889689\n",
      "Mean loss: 0.5516009668260011\n",
      "5/30\n",
      "Accuracy: 0.8326183545273479\n",
      "Mean loss: 0.5192654518623475\n",
      "6/30\n",
      "Accuracy: 0.8382105101884479\n",
      "Mean loss: 0.4862330268491847\n",
      "7/30\n",
      "Accuracy: 0.8428834073847097\n",
      "Mean loss: 0.4576216620483501\n",
      "8/30\n",
      "Accuracy: 0.8492416117665084\n",
      "Mean loss: 0.43479166200081887\n",
      "9/30\n",
      "Accuracy: 0.8548337674276084\n",
      "Mean loss: 0.4167148073061674\n",
      "10/30\n",
      "Accuracy: 0.8619580205301057\n",
      "Mean loss: 0.40211763224525\n",
      "11/30\n",
      "Accuracy: 0.8687758541443236\n",
      "Mean loss: 0.39048882831028653\n",
      "12/30\n",
      "Accuracy: 0.8738317757009346\n",
      "Mean loss: 0.38113472758666295\n",
      "13/30\n",
      "Accuracy: 0.878657882641336\n",
      "Mean loss: 0.3732651784003319\n",
      "14/30\n",
      "Accuracy: 0.8824881262448292\n",
      "Mean loss: 0.36641877321179\n",
      "15/30\n",
      "Accuracy: 0.8863949747203922\n",
      "Mean loss: 0.3603611124969163\n",
      "16/30\n",
      "Accuracy: 0.8913742914049334\n",
      "Mean loss: 0.35501259742284236\n",
      "17/30\n",
      "Accuracy: 0.8933660180787498\n",
      "Mean loss: 0.35043362675762246\n",
      "18/30\n",
      "Accuracy: 0.8959705837291252\n",
      "Mean loss: 0.3467583984525626\n",
      "19/30\n",
      "Accuracy: 0.8973494714263828\n",
      "Mean loss: 0.3440220731707472\n",
      "20/30\n",
      "Accuracy: 0.8987283591236402\n",
      "Mean loss: 0.342020858193511\n",
      "21/30\n",
      "Accuracy: 0.9001838516929677\n",
      "Mean loss: 0.3404219340897338\n",
      "22/30\n",
      "Accuracy: 0.9012563199019458\n",
      "Mean loss: 0.3389556046641517\n",
      "23/30\n",
      "Accuracy: 0.9021755783667841\n",
      "Mean loss: 0.3374653277918186\n",
      "24/30\n",
      "Accuracy: 0.9031714417036923\n",
      "Mean loss: 0.33588522577584545\n",
      "25/30\n",
      "Accuracy: 0.9044737245288801\n",
      "Mean loss: 0.33421325490717546\n",
      "26/30\n",
      "Accuracy: 0.9056994024819979\n",
      "Mean loss: 0.3324926945928423\n",
      "27/30\n",
      "Accuracy: 0.9065420560747663\n",
      "Mean loss: 0.33078448692604673\n",
      "28/30\n",
      "Accuracy: 0.9075379194116746\n",
      "Mean loss: 0.3291089469646988\n",
      "29/30\n",
      "Accuracy: 0.9085337827485828\n",
      "Mean loss: 0.32742019135812817\n",
      "30/30\n",
      "Hidden neurons: 200\n",
      "test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/akakyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:11: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7925540064348092\n",
      "Mean loss: 0.8108746604043497\n",
      "1/30\n",
      "Accuracy: 0.816301516776467\n",
      "Mean loss: 0.6978823349268976\n",
      "2/30\n",
      "Accuracy: 0.829783974260763\n",
      "Mean loss: 0.6338391270934169\n",
      "3/30\n",
      "Accuracy: 0.8358357591542822\n",
      "Mean loss: 0.5829107261464945\n",
      "4/30\n",
      "Accuracy: 0.839895817373985\n",
      "Mean loss: 0.5337288173355714\n",
      "5/30\n",
      "Accuracy: 0.8430366171288494\n",
      "Mean loss: 0.48892111518550474\n",
      "6/30\n",
      "Accuracy: 0.8459476022675042\n",
      "Mean loss: 0.45250424641396064\n",
      "7/30\n",
      "Accuracy: 0.8497012409989275\n",
      "Mean loss: 0.4241532838679355\n",
      "8/30\n",
      "Accuracy: 0.8569020989734947\n",
      "Mean loss: 0.40201532583641353\n",
      "9/30\n",
      "Accuracy: 0.864026352075992\n",
      "Mean loss: 0.3845332337813825\n",
      "10/30\n",
      "Accuracy: 0.8709207905622798\n",
      "Mean loss: 0.3705944425793218\n",
      "11/30\n",
      "Accuracy: 0.87635973647924\n",
      "Mean loss: 0.35939924536936396\n",
      "12/30\n",
      "Accuracy: 0.8819518921403401\n",
      "Mean loss: 0.3503426657173135\n",
      "13/30\n",
      "Accuracy: 0.8857055308717634\n",
      "Mean loss: 0.3429689309722756\n",
      "14/30\n",
      "Accuracy: 0.8909912670445841\n",
      "Mean loss: 0.3369444880242043\n",
      "15/30\n",
      "Accuracy: 0.8942086716715183\n",
      "Mean loss: 0.332010768223325\n",
      "16/30\n",
      "Accuracy: 0.8965068178336142\n",
      "Mean loss: 0.3279444844946972\n",
      "17/30\n",
      "Accuracy: 0.8984219396353608\n",
      "Mean loss: 0.3245580006665931\n",
      "18/30\n",
      "Accuracy: 0.8997242224605485\n",
      "Mean loss: 0.32169646666400264\n",
      "19/30\n",
      "Accuracy: 0.9019457637505746\n",
      "Mean loss: 0.3192031299871049\n",
      "20/30\n",
      "Accuracy: 0.9041673050406006\n",
      "Mean loss: 0.3169103415221323\n",
      "21/30\n",
      "Accuracy: 0.9055461927378581\n",
      "Mean loss: 0.3146792418639644\n",
      "22/30\n",
      "Accuracy: 0.9070782901792555\n",
      "Mean loss: 0.31241565712735553\n",
      "23/30\n",
      "Accuracy: 0.9088402022368622\n",
      "Mean loss: 0.3100706801125053\n",
      "24/30\n",
      "Accuracy: 0.9100658801899801\n",
      "Mean loss: 0.30764293459758635\n",
      "25/30\n",
      "Accuracy: 0.9115213727593074\n",
      "Mean loss: 0.3051678045630203\n",
      "26/30\n",
      "Accuracy: 0.9133598896889842\n",
      "Mean loss: 0.30269684073248976\n",
      "27/30\n",
      "Accuracy: 0.9145089627700321\n",
      "Mean loss: 0.30027937207117356\n",
      "28/30\n",
      "Accuracy: 0.9156580358510801\n",
      "Mean loss: 0.2979377069318609\n",
      "29/30\n",
      "Accuracy: 0.9173433430366171\n",
      "Mean loss: 0.29564416875597316\n",
      "30/30\n",
      "[[0.7459016393442623, 0.7571625555385323, 0.7787651294622338, 0.7975333231193504, 0.8148460242071396, 0.8287115060517849, 0.8356825494101425, 0.8412747050712426, 0.8459476022675042, 0.8503906848475563, 0.8562892599969358, 0.860119503600429, 0.8639497472039221, 0.8660946836218784, 0.8689290638884634, 0.8731423318523058, 0.8772789949440785, 0.88762065267351, 0.8929829937184005, 0.8975026811705225, 0.8994944078443389, 0.9021755783667841, 0.9050099586333691, 0.9086103876206527, 0.910678719166539, 0.9137429140493335, 0.9159644553393596, 0.9195648843266432, 0.9218630304887391, 0.9244675961391144], [0.746667688064961, 0.76405699402482, 0.7829017925540064, 0.7957714110617435, 0.8072621418722231, 0.8189060824268424, 0.8289413206679945, 0.8357591542822124, 0.840508656350544, 0.8461008120116439, 0.8517695725448139, 0.8585874061590317, 0.862953883867014, 0.8667075225984373, 0.8704611613298606, 0.8745212195495633, 0.876972575455799, 0.8809560288034319, 0.8833307798375977, 0.8857055308717634, 0.8867779990807415, 0.8883867013942087, 0.8903784280680251, 0.8916041060211429, 0.8931362034625402, 0.8942852765435881, 0.8949747203922169, 0.896047188601195, 0.8968132373218937, 0.8975026811705225], [0.7695725448138502, 0.7920177723303202, 0.8064194882794545, 0.8165313313926765, 0.826413359889689, 0.8326183545273479, 0.8382105101884479, 0.8428834073847097, 0.8492416117665084, 0.8548337674276084, 0.8619580205301057, 0.8687758541443236, 0.8738317757009346, 0.878657882641336, 0.8824881262448292, 0.8863949747203922, 0.8913742914049334, 0.8933660180787498, 0.8959705837291252, 0.8973494714263828, 0.8987283591236402, 0.9001838516929677, 0.9012563199019458, 0.9021755783667841, 0.9031714417036923, 0.9044737245288801, 0.9056994024819979, 0.9065420560747663, 0.9075379194116746, 0.9085337827485828], [0.7925540064348092, 0.816301516776467, 0.829783974260763, 0.8358357591542822, 0.839895817373985, 0.8430366171288494, 0.8459476022675042, 0.8497012409989275, 0.8569020989734947, 0.864026352075992, 0.8709207905622798, 0.87635973647924, 0.8819518921403401, 0.8857055308717634, 0.8909912670445841, 0.8942086716715183, 0.8965068178336142, 0.8984219396353608, 0.8997242224605485, 0.9019457637505746, 0.9041673050406006, 0.9055461927378581, 0.9070782901792555, 0.9088402022368622, 0.9100658801899801, 0.9115213727593074, 0.9133598896889842, 0.9145089627700321, 0.9156580358510801, 0.9173433430366171]]\n"
     ]
    }
   ],
   "source": [
    "accuracy_all = []\n",
    "loss_all = []\n",
    "time_all = []\n",
    "# hidden_layer = [i for i in range(10, 20)]\n",
    "hidden_layer = [15, 50, 100, 200]\n",
    "\n",
    "epochs = 30\n",
    "\n",
    "for i in hidden_layer:\n",
    "    print('Hidden neurons:', i)\n",
    "    accuracy_i, loss_i, time_i = train(np.array(best_features), y, i, epochs)\n",
    "    accuracy_all.append(accuracy_i)\n",
    "    loss_all.append(loss_i)\n",
    "    time_all.append(time_i)\n",
    "    \n",
    "print(accuracy_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лучшей нейронной сетью оказалась сеть с 15-ю скрытыми нейронами и точностью 0.9274551861498391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
